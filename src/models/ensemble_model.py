import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models
from .fpn import FPN, FeatureFusion
from .losses import KnowledgeDistillationLoss, EnhancedCombinedLoss, AdaptiveFocalLoss
from .contrastive_losses import CombinedAdaptiveContrastiveLoss
from .grad_cam import GradCAM  # å¯¼å…¥Grad-CAMç±»
from .residual_modules import ResidualFeatureFusion  # ğŸ”¥ é˜¶æ®µä¸€ï¼šå¼•å…¥æ®‹å·®ç‰¹å¾èåˆ

class EnhancedInceptionV3(nn.Module):
    """å¢å¼ºç‰ˆInception V3"""
    def __init__(self, num_classes):
        super(EnhancedInceptionV3, self).__init__()
        self.inception = models.inception_v3(
            weights=models.Inception_V3_Weights.IMAGENET1K_V1,
            aux_logits=True
        )
        
        # å†»ç»“éƒ¨åˆ†å±‚
        for param in list(self.inception.parameters())[:-150]:
            param.requires_grad = False
        
        # ç§»é™¤å¤–æŒ‚æ³¨æ„åŠ›æ¨¡å— - æ ¹æ®æ–°çš„æŠ€æœ¯æ–¹æ¡ˆ
        
        # ç‰¹å¾é‡‘å­—å¡”
        self.fpn = FPN(
            in_channels_list=[288, 768, 1280, 2048],
            out_channels=512
        )
        
        # ç‰¹å¾èåˆ
        self.fusion = FeatureFusion(channels=512)
        
        # åˆ†ç±»å¤´
        self.fc = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
    
    def _extract_features(self, x):
        """æå–Inception V3çš„ä¸­é—´ç‰¹å¾"""
        features = []
        
        # ç¬¬ä¸€é˜¶æ®µï¼šConv2d layers
        x = self.inception.Conv2d_1a_3x3(x)  # 32
        x = self.inception.Conv2d_2a_3x3(x)  # 32
        x = self.inception.Conv2d_2b_3x3(x)  # 64
        x = F.max_pool2d(x, kernel_size=3, stride=2)
        x = self.inception.Conv2d_3b_1x1(x)  # 80
        x = self.inception.Conv2d_4a_3x3(x)  # 192
        x = F.max_pool2d(x, kernel_size=3, stride=2)
        
        # ç¬¬äºŒé˜¶æ®µï¼šMixed_5 layers (288 channels)
        x = self.inception.Mixed_5b(x)  # 256
        x = self.inception.Mixed_5c(x)  # 288
        x = self.inception.Mixed_5d(x)  # 288
        features.append(x)  # 288 channels
        
        # ç¬¬ä¸‰é˜¶æ®µï¼šMixed_6 layers (768 channels)
        x = self.inception.Mixed_6a(x)  # 768
        x = self.inception.Mixed_6b(x)  # 768
        x = self.inception.Mixed_6c(x)  # 768
        x = self.inception.Mixed_6d(x)  # 768
        x = self.inception.Mixed_6e(x)  # 768
        features.append(x)  # 768 channels
        
        # ä¿å­˜è¾…åŠ©åˆ†ç±»å™¨çš„è¾“å…¥
        aux = None
        if self.training and self.inception.aux_logits:
            aux = self.inception.AuxLogits(x)
        
        # ç¬¬å››é˜¶æ®µï¼šMixed_7a (1280 channels)
        x = self.inception.Mixed_7a(x)  # 1280
        features.append(x)  # 1280 channels
        
        # ç¬¬äº”é˜¶æ®µï¼šMixed_7b/c (2048 channels)
        x = self.inception.Mixed_7b(x)  # 2048
        x = self.inception.Mixed_7c(x)  # 2048
        features.append(x)  # 2048 channels
        
        # ç§»é™¤æ³¨æ„åŠ›æœºåˆ¶ï¼Œä¿æŒåŸå§‹ç‰¹å¾
        
        return features, aux
    
    def forward(self, x):
        # æå–ç‰¹å¾
        features, aux = self._extract_features(x)
        
        # ç‰¹å¾é‡‘å­—å¡”å¢å¼º
        fpn_features = self.fpn(features)
        
        # ç‰¹å¾èåˆ
        fused_features = self.fusion(fpn_features[0], fpn_features[-1])
        
        # åˆ†ç±»
        x = self.fc(fused_features)
        
        if self.training and aux is not None:
            return x, fused_features, aux
        return x, fused_features

class EfficientNetB4Enhanced(nn.Module):
    """å¢å¼ºç‰ˆEfficientNet-B4"""
    def __init__(self, num_classes):
        super(EfficientNetB4Enhanced, self).__init__()
        self.efficientnet = models.efficientnet_b4(
            weights=models.EfficientNet_B4_Weights.IMAGENET1K_V1
        )
        
        # EfficientNet-B4çš„ç‰¹å¾å±‚é€šé“æ•°
        self.channel_sizes = [24, 56, 160, 1792]
        
        # ç§»é™¤å¤–æŒ‚æ³¨æ„åŠ›æ¨¡å—ï¼Œä¿ç•™EfficientNetåŸç”ŸSEæ¨¡å—
        
        # ç‰¹å¾é¢„å¤„ç†å±‚ï¼ˆç»Ÿä¸€ç©ºé—´ç»´åº¦å’Œé€šé“æ•°ï¼‰
        self.preprocess = nn.ModuleList([
            nn.Sequential(
                nn.Conv2d(24, 288, 1),
                nn.BatchNorm2d(288),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool2d((35, 35))
            ),
            nn.Sequential(
                nn.Conv2d(56, 768, 1),
                nn.BatchNorm2d(768),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool2d((17, 17))
            ),
            nn.Sequential(
                nn.Conv2d(160, 1280, 1),
                nn.BatchNorm2d(1280),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool2d((8, 8))
            ),
            nn.Sequential(
                nn.Conv2d(1792, 2048, 1),
                nn.BatchNorm2d(2048),
                nn.ReLU(inplace=True),
                nn.AdaptiveAvgPool2d((8, 8))
            )
        ])
        
        # ç‰¹å¾é‡‘å­—å¡”
        self.fpn = FPN(
            in_channels_list=[288, 768, 1280, 2048],
            out_channels=512
        )
        
        # ç‰¹å¾èåˆ
        self.fusion = FeatureFusion(channels=512)
        
        # åˆ†ç±»å¤´
        self.fc = nn.Sequential(
            nn.AdaptiveAvgPool2d((1, 1)),
            nn.Flatten(),
            nn.Linear(512, 1024),
            nn.BatchNorm1d(1024),
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),
            nn.Linear(1024, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(inplace=True),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )
        
        # å†»ç»“éƒ¨åˆ†å±‚
        for param in list(self.efficientnet.parameters())[:-100]:
            param.requires_grad = False
    
    def _extract_features(self, x):
        """æå–EfficientNet-B4çš„ä¸­é—´ç‰¹å¾"""
        features = []
        current_feature = x
        
        # è·å–ç‰¹å¾æå–å™¨çš„æ‰€æœ‰å±‚
        layers = list(self.efficientnet.features)
        
        # ç¬¬ä¸€é˜¶æ®µï¼š24é€šé“
        for layer in layers[:2]:
            current_feature = layer(current_feature)
        features.append(current_feature)
        
        # ç¬¬äºŒé˜¶æ®µï¼š56é€šé“
        for layer in layers[2:4]:
            current_feature = layer(current_feature)
        features.append(current_feature)
        
        # ç¬¬ä¸‰é˜¶æ®µï¼š160é€šé“
        for layer in layers[4:6]:
            current_feature = layer(current_feature)
        features.append(current_feature)
        
        # ç¬¬å››é˜¶æ®µï¼š1792é€šé“
        for layer in layers[6:]:
            current_feature = layer(current_feature)
        features.append(current_feature)
        
        # ä¿ç•™EfficientNetåŸç”Ÿç‰¹å¾ï¼Œä¸æ·»åŠ å¤–æŒ‚æ³¨æ„åŠ›
        
        # é¢„å¤„ç†ç‰¹å¾ï¼Œä½¿å…¶ä¸Inception V3çš„ç‰¹å¾ç»´åº¦åŒ¹é…
        processed_features = []
        for feat, preprocess in zip(features, self.preprocess):
            processed_features.append(preprocess(feat))
        
        return processed_features
    
    def forward(self, x):
        # ç¡®ä¿è¾“å…¥å°ºå¯¸æ­£ç¡® (EfficientNet-B4éœ€è¦380x380)
        if x.shape[-1] != 380:
            x = F.interpolate(x, size=(380, 380), mode='bilinear', align_corners=True)
        
        # æå–å¹¶é¢„å¤„ç†ç‰¹å¾
        features = self._extract_features(x)
        
        # ç‰¹å¾é‡‘å­—å¡”å¢å¼º
        fpn_features = self.fpn(features)
        
        # ç‰¹å¾èåˆ
        fused_features = self.fusion(fpn_features[0], fpn_features[-1])
        
        # åˆ†ç±»
        x = self.fc(fused_features)
        
        return x, fused_features

class EnsembleModel(nn.Module):
    """é›†æˆæ¨¡å‹"""
    def __init__(self, num_classes, temperature=4.0):
        super(EnsembleModel, self).__init__()
        self.inception = EnhancedInceptionV3(num_classes)
        self.efficientnet = EfficientNetB4Enhanced(num_classes)
        
        # ä½¿ç”¨å¢å¼ºç‰ˆç»„åˆæŸå¤±å‡½æ•°
        self.combined_loss = EnhancedCombinedLoss(num_classes, feat_dim=512)
        self.kd_loss = KnowledgeDistillationLoss(temperature=temperature)
        self.ce = nn.CrossEntropyLoss()
        
        # æ·»åŠ å¯¹æ¯”å­¦ä¹ å’Œé¢†åŸŸè‡ªé€‚åº”æŸå¤±
        self.adaptive_contrastive = CombinedAdaptiveContrastiveLoss(
            feature_dim=512,
            num_classes=num_classes,
            temperature=0.07,
            memory_bank_size=4096
        )
        
        # Grad-CAM
        self.grad_cam = None  # Grad-CAMå®ä¾‹å°†ä¼šåœ¨forwardä¸­åˆ›å»º
        
        # æ¨¡å‹èåˆæƒé‡ - åˆå§‹åŒ–ä¸ºç›¸ç­‰æƒé‡
        self.weight_inception = nn.Parameter(torch.FloatTensor([0.5]))
        self.weight_efficientnet = nn.Parameter(torch.FloatTensor([0.5]))
        
        # ç‰¹å¾å¯¹é½å±‚ - ç»Ÿä¸€åˆ°ç›¸åŒå°ºå¯¸ HÃ—WÃ—C
        self.feature_alignment = nn.ModuleDict({
            'inception': nn.Sequential(
                nn.AdaptiveAvgPool2d((8, 8)),  # ç»Ÿä¸€ç©ºé—´å°ºå¯¸åˆ°8x8
                nn.Conv2d(512, 512, 1),
                nn.BatchNorm2d(512),
                nn.ReLU(inplace=True)
            ),
            'efficientnet': nn.Sequential(
                nn.AdaptiveAvgPool2d((8, 8)),  # ç»Ÿä¸€ç©ºé—´å°ºå¯¸åˆ°8x8
                nn.Conv2d(512, 512, 1),
                nn.BatchNorm2d(512),
                nn.ReLU(inplace=True)
            )
        })
        
        # åˆ†æ”¯çº§é—¨æ§
        self.branch_gating = BranchGating(feature_dim=512)
        
        # ğŸ”¥ é˜¶æ®µä¸€æ”¹è¿›ï¼šä½¿ç”¨æ®‹å·®å¼ç‰¹å¾èåˆ
        self.feature_fusion = ResidualFeatureFusion(feature_dim=512)
        # åŸç‰ˆï¼šself.feature_fusion = AdaptiveFeatureFusion(feature_dim=512, fusion_type='weighted')
        
        # æ®‹å·®å¼æ³¨æ„åŠ›
        self.residual_attention = ResidualAttentionBlock(feature_dim=512)
        
        # æ·»åŠ æŠ•å½±å¤´ï¼Œç”¨äºå¯¹æ¯”å­¦ä¹ 
        self.projection = nn.Sequential(
            nn.Linear(512, 512),
            nn.ReLU(inplace=True),
            nn.Linear(512, 128)
        )
        
        # å­˜å‚¨ç±»åˆ«å‡†ç¡®ç‡
        self.class_accuracies = None
    
    def forward(self, x, labels=None, alpha=1.0, class_accuracies=None, contrast_weight=0.1):
        # æ›´æ–°ç±»åˆ«å‡†ç¡®ç‡
        if class_accuracies is not None:
            self.class_accuracies = class_accuracies
            
        if self.training and labels is not None:
            # è·å–Inceptionè¾“å‡º
            inception_outputs = self.inception(x)
            if len(inception_outputs) == 3:
                inception_logits, inception_features, aux_logits = inception_outputs
            else:
                inception_logits, inception_features = inception_outputs
                aux_logits = None
            
            # è·å–EfficientNetè¾“å‡º
            efficientnet_logits, efficientnet_features = self.efficientnet(x)
            
            # ç‰¹å¾å¯¹é½åˆ°ç»Ÿä¸€å°ºå¯¸ HÃ—WÃ—C
            aligned_inception = self.feature_alignment['inception'](inception_features)
            aligned_efficientnet = self.feature_alignment['efficientnet'](efficientnet_features)
            
            # åˆ†æ”¯çº§é—¨æ§
            gated_features = self.branch_gating(aligned_inception, aligned_efficientnet)
            
            # è‡ªé€‚åº”ç‰¹å¾èåˆ
            fused_features = self.feature_fusion(aligned_inception, aligned_efficientnet)
            
            # æ®‹å·®å¼æ³¨æ„åŠ›
            attention_features = self.residual_attention(fused_features)
            
            # åŠ æƒèåˆ
            weights = F.softmax(torch.stack([
                self.weight_inception,
                self.weight_efficientnet
            ]), dim=0)
            
            ensemble_logits = (
                weights[0] * inception_logits +
                weights[1] * efficientnet_logits
            )
            
            # è®¡ç®—å„ä¸ªæ¨¡å‹çš„æŸå¤±ï¼Œä½¿ç”¨å¯¹é½åçš„ç‰¹å¾
            inception_loss = self.combined_loss(
                aligned_inception, 
                inception_logits, 
                labels, 
                class_accuracies=self.class_accuracies
            )
            
            efficientnet_loss = self.combined_loss(
                aligned_efficientnet, 
                efficientnet_logits, 
                labels,
                class_accuracies=self.class_accuracies
            )
            
            # ä½¿ç”¨è‡ªé€‚åº”Focal Loss
            ce_loss = AdaptiveFocalLoss(num_classes=inception_logits.size(1), gamma=1.5, smoothing=0.2)
            if self.class_accuracies is not None:
                ce_loss.update_weights(self.class_accuracies)
            ensemble_loss = ce_loss(ensemble_logits, labels)
            
            # è®¡ç®—çŸ¥è¯†è’¸é¦æŸå¤±
            kd_loss = self.kd_loss(efficientnet_logits, inception_logits, labels)
            
            # ç”Ÿæˆå¯¹æ¯”å­¦ä¹ ç‰¹å¾ï¼Œä½¿ç”¨æ³¨æ„åŠ›å¢å¼ºåçš„ç‰¹å¾
            inception_feat = F.adaptive_avg_pool2d(aligned_inception, (1, 1)).squeeze(-1).squeeze(-1)
            efficientnet_feat = F.adaptive_avg_pool2d(aligned_efficientnet, (1, 1)).squeeze(-1).squeeze(-1)
            attention_feat = F.adaptive_avg_pool2d(attention_features, (1, 1)).squeeze(-1).squeeze(-1)
            
            # æŠ•å½±ç‰¹å¾
            proj_inception = self.projection(inception_feat)
            proj_efficientnet = self.projection(efficientnet_feat)
            
            # è®¡ç®—å¯¹æ¯”å­¦ä¹ å’Œé¢†åŸŸè‡ªé€‚åº”æŸå¤±ï¼Œä½¿ç”¨æ³¨æ„åŠ›å¢å¼ºç‰¹å¾
            contrast_domain_loss = self.adaptive_contrastive(
                features=self.projection(attention_feat),  # ä½¿ç”¨æ³¨æ„åŠ›å¢å¼ºåçš„ç‰¹å¾
                labels=labels,
                domain_features=torch.cat([inception_feat, efficientnet_feat, attention_feat], dim=0),
                alpha=alpha
            )
            
            # æ€»æŸå¤±ï¼Œä½¿ç”¨åŠ¨æ€å¯¹æ¯”å­¦ä¹ æƒé‡
            loss = (inception_loss + 
                   efficientnet_loss + 
                   ensemble_loss + 
                   0.5 * kd_loss + 
                   contrast_weight * 1.5 * contrast_domain_loss)  # ä½¿ç”¨åŠ¨æ€å¯¹æ¯”å­¦ä¹ æƒé‡
            
            # æ·»åŠ è¾…åŠ©æŸå¤±
            if aux_logits is not None:
                aux_loss = ce_loss(aux_logits, labels)
                loss = loss + 0.4 * aux_loss
            
            return ensemble_logits, loss
        else:
            # æ¨ç†æ¨¡å¼
            inception_logits, inception_features = self.inception(x)
            efficientnet_logits, efficientnet_features = self.efficientnet(x)
            
            # ç‰¹å¾å¯¹é½åˆ°ç»Ÿä¸€å°ºå¯¸ HÃ—WÃ—C
            aligned_inception = self.feature_alignment['inception'](inception_features)
            aligned_efficientnet = self.feature_alignment['efficientnet'](efficientnet_features)
            
            # åˆ†æ”¯çº§é—¨æ§
            gated_features = self.branch_gating(aligned_inception, aligned_efficientnet)
            
            # è‡ªé€‚åº”ç‰¹å¾èåˆ
            fused_features = self.feature_fusion(aligned_inception, aligned_efficientnet)
            
            # æ®‹å·®å¼æ³¨æ„åŠ›
            attention_features = self.residual_attention(fused_features)
            
            # åŠ æƒèåˆlogits
            weights = F.softmax(torch.stack([
                self.weight_inception,
                self.weight_efficientnet
            ]), dim=0)
            
            ensemble_logits = (
                weights[0] * inception_logits +
                weights[1] * efficientnet_logits
            )
            
            # åˆ›å»º Grad-CAM å®ä¾‹ï¼Œä½¿ç”¨æœ€åä¸€ä¸ªå·ç§¯å±‚ä½œä¸ºç›®æ ‡å±‚
            self.grad_cam = GradCAM(self, self.inception.inception.Mixed_7c) 
            
            return ensemble_logits, attention_features  # è¿”å›æ³¨æ„åŠ›å¢å¼ºåçš„ç‰¹å¾


class AdaptiveFeatureFusion(nn.Module):
    """è‡ªé€‚åº”ç‰¹å¾èåˆæ¨¡å—"""
    def __init__(self, feature_dim=512, fusion_type='weighted'):
        super(AdaptiveFeatureFusion, self).__init__()
        self.fusion_type = fusion_type
        
        if fusion_type == 'concat':
            # æ‹¼æ¥åçš„é€šé“æ•°æ˜¯åŸæ¥çš„2å€
            self.fusion_conv = nn.Sequential(
                nn.Conv2d(feature_dim * 2, feature_dim, 1),
                nn.BatchNorm2d(feature_dim),
                nn.ReLU(inplace=True)
            )
        elif fusion_type == 'weighted':
            # é€é€šé“åŠ æƒ
            self.channel_weights = nn.Sequential(
                nn.AdaptiveAvgPool2d(1),
                nn.Conv2d(feature_dim * 2, feature_dim, 1),
                nn.Sigmoid()
            )
    
    def forward(self, f1, f2):
        if self.fusion_type == 'concat':
            fused = torch.cat([f1, f2], dim=1)
            return self.fusion_conv(fused)
        else:
            combined = torch.cat([f1, f2], dim=1)
            weights = self.channel_weights(combined)
            return f1 * weights + f2 * (1 - weights)


class ResidualAttentionBlock(nn.Module):
    """æ®‹å·®å¼æ³¨æ„åŠ›æ¨¡å—"""
    def __init__(self, feature_dim=512, reduction=16):
        super(ResidualAttentionBlock, self).__init__()
        
        # é€šé“æ³¨æ„åŠ›ï¼šå…¨å±€å¹³å‡æ± åŒ– â†’ MLP â†’ Sigmoid
        self.channel_attention = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(feature_dim, feature_dim // reduction, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(feature_dim // reduction, feature_dim, 1),
            nn.Sigmoid()
        )
        
        # è½»é‡ç©ºé—´æ³¨æ„åŠ›ï¼šdepthwise 3x3 conv + Sigmoid
        self.spatial_attention = nn.Sequential(
            nn.Conv2d(feature_dim, feature_dim, 3, padding=1, groups=feature_dim),
            nn.BatchNorm2d(feature_dim),
            nn.ReLU(inplace=True),
            nn.Conv2d(feature_dim, 1, 1),
            nn.Sigmoid()
        )
        
        # æ®‹å·®è¿æ¥æƒé‡
        self.alpha = nn.Parameter(torch.tensor(0.3))  # é€šé“æ³¨æ„åŠ›æƒé‡
        self.beta = nn.Parameter(torch.tensor(0.3))   # ç©ºé—´æ³¨æ„åŠ›æƒé‡
    
    def forward(self, x):
        # é€šé“æ³¨æ„åŠ›ï¼šy = x * s_c + xï¼ˆæ®‹å·®ï¼‰
        s_c = self.channel_attention(x)
        channel_refined = x * s_c + x  # æ®‹å·®è¿æ¥
        
        # ç©ºé—´æ³¨æ„åŠ›ï¼šåŒæ ·æ®‹å·®
        s_s = self.spatial_attention(channel_refined)
        spatial_refined = channel_refined * s_s + channel_refined
        
        # æœ€ç»ˆæ®‹å·®èåˆï¼Œé˜²æ­¢è¿‡åº¦è°ƒåˆ¶
        return self.alpha * spatial_refined + (1 - self.alpha) * x


class BranchGating(nn.Module):
    """åˆ†æ”¯çº§é—¨æ§æœºåˆ¶"""
    def __init__(self, feature_dim=512):
        super(BranchGating, self).__init__()
        
        # åˆ†æ”¯é‡è¦æ€§è¯„ä¼°
        self.branch_evaluator = nn.Sequential(
            nn.AdaptiveAvgPool2d(1),
            nn.Conv2d(feature_dim * 2, feature_dim, 1),
            nn.ReLU(inplace=True),
            nn.Conv2d(feature_dim, 2, 1),  # è¾“å‡ºä¸¤ä¸ªåˆ†æ”¯çš„æƒé‡
            nn.Softmax(dim=1)
        )
        
        # åˆ†æ”¯ç‰¹å¾å¢å¼º
        self.branch_enhancer = nn.ModuleDict({
            'inception': nn.Sequential(
                nn.Conv2d(feature_dim, feature_dim, 3, padding=1),
                nn.BatchNorm2d(feature_dim),
                nn.ReLU(inplace=True)
            ),
            'efficientnet': nn.Sequential(
                nn.Conv2d(feature_dim, feature_dim, 3, padding=1),
                nn.BatchNorm2d(feature_dim),
                nn.ReLU(inplace=True)
            )
        })
    
    def forward(self, f_inception, f_efficientnet):
        # è¯„ä¼°åˆ†æ”¯é‡è¦æ€§
        combined = torch.cat([f_inception, f_efficientnet], dim=1)
        branch_weights = self.branch_evaluator(combined)  # [B, 2, 1, 1]
        
        # å¢å¼ºå„åˆ†æ”¯ç‰¹å¾
        enhanced_inception = self.branch_enhancer['inception'](f_inception)
        enhanced_efficientnet = self.branch_enhancer['efficientnet'](f_efficientnet)
        
        # é—¨æ§èåˆ
        gated_inception = enhanced_inception * branch_weights[:, 0:1]
        gated_efficientnet = enhanced_efficientnet * branch_weights[:, 1:2]
        
        return gated_inception + gated_efficientnet 